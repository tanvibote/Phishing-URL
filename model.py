# -*- coding: utf-8 -*-
"""ML term project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qQEpJE7pnoa9RUf4woNycfTDMMhOMF0B

importing important libraries
"""

import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score

"""importing the dataset"""

#Load the dataset into a pandas dataframe
df = pd.read_csv('/content/sample_data/Phishing_Legitimate_full.csv')

# Drop any duplicates
df.drop_duplicates(inplace=True)

# Drop any irrelevant columns
df.drop(['id'], axis=1, inplace=True)

# Check for missing values
print(df.isnull().sum())

# Replace any missing values with a default value or the mean/median of the column
df.fillna(value=-1, inplace=True)

#renaming the labels class
df.rename(columns = {'CLASS_LABEL' : 'labels'}, inplace = True)

# Plot the distribution of the target variable
sns.countplot(x='labels', data=df)
plt.show()

# Plot the correlation matrix
corr = df.corr()

# Set the plot size and create a heatmap of the correlation matrix
plt.figure(figsize=(30, 20))
sns.heatmap(corr, cmap='coolwarm', annot=True, fmt='.2f')

#finding absolute correlation values for each feature with respect to the target values
corr_values = abs(corr['labels'])

#sort the features in descending order based on corr values
sorted_features = corr_values.sort_values(ascending=False)

#choosing top k features
k=10
top_k_features = sorted_features[:k+1] #excluding the target variable from the list

print("Top 10 features with high correlation values with target variable")
print(top_k_features)

print("Highest correlation valued features from top 10: ")
for feature, corr_value in top_k_features.items():
  print(f"Feature: {feature}")
  print(f"Sign of correlation: {'Positive' if corr_value>0 else 'Negative'}")
  print(f"Magnitude of correlation: {corr_value}")
  print()

"""features form highest to lowest correlation values"""

print("Features sorted in descending order of correlation values:")
print(sorted_features)

"""dividing the dataset in X(features) and Y(labels) and then training and testing dataset"""

X = df.iloc[:, :-1]
y = df.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

df.info()

"""using logistic regression to train the dataset"""

# Create logistic regression model
model = LogisticRegression(max_iter=10000)

# Train the model
model.fit(X_train, y_train)

# Make predictions on testing set
y_pred = model.predict(X_test)

# Make predictions on training set
y_train_pred = model.predict(X_train)

# Evaluate model performance
print("Accuracy:", accuracy_score(y_test, y_pred))

#Calculating the performance metrics

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Precision: ", (precision))
print("Recall: ", (recall))
print("F1 Score: ", (f1))

#accuracy
train_acc = accuracy_score(y_train, y_train_pred)
test_acc = accuracy_score(y_test, y_pred)

train_acc, test_acc

# Plot training and testing error as line graphs
train_epochs = range(1, len(y_train_pred) + 1)
test_epochs = range(1, len(y_pred) + 1)
plt.plot(train_epochs, [train_acc] * len(train_epochs), 'b', label='Training Accuracy')
plt.plot(test_epochs, [test_acc] * len(test_epochs), 'r', label='Testing Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Error')
plt.title('Training and Testing Accuracy')
plt.legend()
plt.show()

#Errors
train_err = 1 - train_acc
test_err = 1 - test_acc

print("Training error: ", train_err)
print("Testing error: ", test_err)

#plotting the error graphs
train_epochs = range(1, len(y_train_pred) + 1)
test_epochs = range(1, len(y_pred) + 1)
plt.plot(train_epochs, y_train != y_train_pred, 'b', label='Training Error')
plt.plot(test_epochs, y_test != y_pred, 'r', label='Testing Error')
plt.xlabel('Epochs')
plt.ylabel('Error')
plt.title('Training and Testing Error')
plt.legend()
plt.show()

# Plot training and testing error as line graphs
train_epochs = range(1, len(y_train_pred) + 1)
test_epochs = range(1, len(y_pred) + 1)
plt.plot(train_epochs, [train_err] * len(train_epochs), 'b', label='Training Error')
plt.plot(test_epochs, [test_err] * len(test_epochs), 'r', label='Testing Error')
plt.xlabel('Epochs')
plt.ylabel('Error')
plt.title('Training and Testing Error')
plt.legend()
plt.show()

# Get the top 10 entries from the dataset
top_10 = df.head(10)

# Extract the feature values for the top 10 entries
X_top_10 = top_10.drop("labels", axis=1)

# Predict the labels for the top 10 entries
predictions = model.predict(X_top_10)

# Print the predicted labels
print(predictions)

for i in range(len(predictions)):
  if predictions[i] == 1:
    print("It is a phishing site. Don't visit it again")

  else:
    print("It is not a phishing site. Its safe to explore")

"""taking user input for all the features in the dataset"""

# Get user inputs
input_features = []
for feature in X.columns:
    value = input(f"Enter the value for {feature}: ")
    input_features.append(float(value))

# # Create the logistic regression model and train it on the full dataset
# model = LogisticRegression(max_iter=10000)
# model.fit(X_new, y_new)

# Make predictions on the user inputs
input_array = np.array(input_features).reshape(1, -1)
prediction = model.predict(input_array)

# Print the prediction
if prediction == 1:
    print("It is a phishing site. Don't visit it again")
else:
    print("It is not a phishing site. Its safe to explore")

"""training model on new dataset"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import pickle

new_df = pd.read_csv('/content/sample_data/phishing_new_dataset1.csv')

#renaming the labels class
new_df.rename(columns = {'CLASS_LABEL' : 'labels'}, inplace = True)

X_new = new_df.iloc[:, :-1]
y_new = new_df.iloc[:, -1]

print("X_new: \n", X, "\n")
print("y_new: \n", y, "\n")

X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, y_new, test_size = 0.2, random_state = 42)
print("X_train_new: ", np.shape(X_train_new))
print("y_train_new: ", np.shape(y_train_new))
print("X_test_new: ", np.shape(X_test_new))
print("y_test_new: ", np.shape(y_test_new))


#NOTE: This dataset only contains the features which are easy to understand by anybody

# Create logistic regression model
model_new = LogisticRegression(max_iter=10000)

# Train the model
model_new.fit(X_train_new, y_train_new)

# Make predictions on testing set
y_pred_new = model_new.predict(X_test_new)

# Evaluate model performance
accuracy_new = accuracy_score(y_test_new, y_pred_new)
precision_new = precision_score(y_test_new, y_pred_new)
recall_new = recall_score(y_test_new, y_pred_new)
f1_new = f1_score(y_test_new, y_pred_new)

print("Accuracy:", (accuracy_new))
print("Precision: ", (precision_new))
print("Recall: ", (recall_new))
print("F1 Score: ", (f1_new))

# #dumping the model in pickle file
# pickle.dump(model, open('proj_model.pkl', 'wb'))    #wb = writes in the file
# pic_model = pickle.load(open('proj_model.pkl', 'rb'))   #rb = reads the file

# Get the top 10 entries from the dataset
top_10_new = new_df.head(10)

# Extract the feature values for the top 10 entries
X_top_10_new = top_10_new.drop('labels', axis=1)

# Predict the labels for the top 10 entries
predictions_new = model_new.predict(X_top_10_new)

# Print the predicted labels
print(predictions_new)

for i in range(len(predictions_new)):
  if predictions_new[i] == 1:
    print("It is a phishing site. Don't visit it again")

  else:
    print("It is not a phishing site. Its safe to explore")

"""taking user inputs on new data

The dataset has 16 columns which are understandable by anyone and are selected based on the correlation matrix values
"""

# Get user inputs
input_features = []
for feature in X_new.columns:
    value = input(f"Enter the value for {feature}: ")
    input_features.append(float(value))

# Create the logistic regression model and train it on the full dataset
model_new = LogisticRegression(max_iter=10000)
model_new.fit(X_new, y_new)

# Make predictions on the user inputs
input_array = np.array(input_features).reshape(1, -1)
prediction = model_new.predict(input_array)

# Print the prediction
if prediction == 1:
    print("It is a phishing site. Don't visit it again")
else:
    print("It is not a phishing site. Its safe to explore")

